---
title: "Calculating NCI Comorbidity Index"
author: "Miriam Hu and Naichen Ni"
date: "Dec. 5, 2019"
header-includes:
  - \usepackage{booktabs}
  - \usepackage{longtable}
  - \usepackage{array}
  - \usepackage{multirow}
  - \usepackage{wrapfig}
  - \usepackage{float}
  - \usepackage{pdflscape}
  - \usepackage{tabu}
  - \usepackage{threeparttable}
  - \usepackage{threeparttablex}
  - \usepackage[normalem]{ulem}
  - \usepackage{makecell}
  - \usepackage{xcolor}
output: beamer_presentation
---

```{r setup, include = FALSE}
library(knitr)
  opts_chunk$set(echo = FALSE, cache = TRUE, autodep = TRUE, 
                 message = FALSE, warning = FALSE)
library(tidyverse)
library(plyr)
library(readxl)
library(kableExtra)
library(comorbidity)
library(Matrix)
```

## Introduction

**Charlson Comorbidity Index:** most widely used measure of comorbid diseases

- First created in 1987
- Ranges from 0 to 24
- Each comorbid disease is assigned to a weight according to risk of death.
- e.g. Diabetes or chronic liver disease add 1 point to the score, while metastatic cancer or AIDS contribute 6 points.
- R package **comorbidity** can calculate the Charlson.

What if your dataset only had cancer patients?

## NCI Comorbidity Index:
\begin{columns}
  \begin{column}{0.34\textwidth}
    \begin{itemize}
      \item Excludes tumors, leukemias, and lymphomas
      \item Slightly different weighting scheme (e.g. renal disease has a score of 1.60 instead of 2)
    \end{itemize}
  \end{column}
  \begin{column}{0.64\textwidth}
    ```{r weights-vector}
    weights.full <- read_csv("weights-full.csv")
    weights.full %>% kable() %>% row_spec(0, bold = TRUE)
    ```
  \end{column}
\end{columns}

## Example Data

```{r example-data}
# Clean the example data and write to csv for presentation -----
# example <- read_csv("example_data.csv")
# example <- example %>% subset(DIAGNOSIS_CODE_TYPE == "ICD-10")
# example <- example %>% subset(select = -DIAGNOSIS_CODE_TYPE)
# example$id <- sample(example$PATIENT_ID)
# example <- example %>% subset(select = -PATIENT_ID)
# example <- example %>% select(id, everything())
# example <- example %>% arrange(id)
# write_csv(example, "example_data.csv")

example <- read_csv("example-data.csv")
kable(example[1:8, ]) %>% row_spec(0, bold = TRUE) %>% column_spec(3, width = "20em")
```

## Charlson Index for Example Data

```{r charlson}
cmb <- comorbidity(x = example, id = "id", code = "code", score = "charlson", assign0 = TRUE)
print.cmb <- kable(cmb[1:15, c(1:18, 21)])
print.cmb %>% kable_styling(latex_options = "scale_down") %>% row_spec(0, bold = TRUE)
```

## Steps

1. Match the ICD codes with the disease categories in the NCI Comorbidity Index
2. Merge NCI Comorbidity Index and reshape
3. Transform into sparse matrix and calculate weighted score

## Steps 1 and 2

\begin{columns}
  \begin{column}{0.48\textwidth}
  $\textbf{Step 1:}$ Match the ICD codes with the disease categories in the NCI Comorbidity Index
  \vspace{2em}
    ```{r step1}
    load(file = "sysdata.rda")
    weights <-read_csv("weights.csv")
    tidy <- function(x, code) {
      ### Upper case all codes
      x[[code]] <- toupper(x[[code]])
      
      ### Remove non-alphanumeric characters
      x[[code]] <- gsub(pattern = "[^[:alnum:]]", x = x[[code]], replacement = "")
      
      ### Return x
      return(x)
    }
    x <-tidy(x = example, code = "code")
    icd = "icd10"
    regex <- lofregex[["charlson"]][[icd]]
      
    ### Subset only 'id' and 'code' columns
    if (data.table::is.data.table(x)) {
      x <- x[, c("id", "code"), with = FALSE]
    } else {
      x <- x[, c("id", "code")]
    }
      
    ### Turn x into a DT
    data.table::setDT(x)
      
    loc <- sapply(regex, grep, unique(x[["code"]]), value = TRUE)
    loc <- utils::stack(loc)
    names(loc)[1] <- "code"
    kable(loc[sample(1:30, 9), ], row.names = FALSE) %>% row_spec(0, bold = TRUE)
    ```
  \end{column}
  \begin{column}{0.48\textwidth}
  $\textbf{Step 2:}$ Merge NCI Comorbidity Index and reshape
  \end{column}
\end{columns}

```{r step2}
x <- tidy(x = example, code = "code")
icd = "icd10"
regex <- lofregex[["charlson"]][[icd]]
  
### Subset only 'id' and 'code' columns
if (data.table::is.data.table(x)) {
  x <- x[, c("id", "code"), with = FALSE]
} else {
  x <- x[, c("id", "code")]
}
  
### Turn x into a DT
data.table::setDT(x)
  
loc <- sapply(regex, grep, unique(x[["code"]]), value = TRUE)
loc <- utils::stack(loc)
names(loc)[1] <- "code"
x <- merge(x, loc, all.x = TRUE, allow.cartesian = TRUE)
x[["code"]] <- NULL
x <- unique(x)
  
### Spread wide
xin <- x[, c("id", "ind"), with = FALSE]
xin[, value := 1L]
x <- data.table::dcast.data.table(xin, stats::as.formula(paste("id", "~ ind")), fill = 0)
x[["NA"]] <- NULL
  
### Add missing columns
for (col in names(regex)) {
  if (is.null(x[[col]])) x[[col]] <- 0
}
data.table::setcolorder(x, c("id", names(regex)))
### Turn internal DT into a DF
data.table::setDF(x)
part_x <- kable(x[1:15,1:15])
# part_x %>% kable_styling(latex_options = "scale_down") %>% row_spec(0, bold = TRUE)
```

## Step 3: Transform into sparse matrix and calculate wscore

```{r step3, echo = TRUE}
x_mat <- Matrix(as.matrix(x[, 2:ncol(x)]), sparse = T)
weight_vec <- as.matrix(weights$weight)
x$wscore <- as.vector(x_mat%*%weight_vec)
```

```{r print-step3}
part_x <- kable(x[1:10,1:16])
part_x %>% kable_styling(latex_options = "scale_down") %>% row_spec(0, bold = TRUE)
```

## Time complexity of sparse matrix multiplication

**Our method:**

- $\mathbf{A}_{n \times k}$ (sparse matrix with $q$ non-zero elements)
- $\mathbf{b}_{k \times 1}$ (dense vector)

The operation $\mathbf{Ab}$ has time complexity $O(q)$.

**Comorbidity package method:**

If $\mathbf{A}_{n \times k}$ is instead stored as a dense matrix, then  $\mathbf{Ab}$ is $O(nk)$.

\vspace{3em}

\begin{columns}
  \begin{column}{0.48\textwidth}
    \textit{Our function:}
    \includegraphics[width=\textwidth]{real_time_ours.png}
  \end{column}
  \begin{column}{0.48\textwidth}
    \textit{Comorbidity function:}
    \includegraphics[width=\textwidth]{real_time_cmb.png}
  \end{column}
\end{columns}

## Simulated Data

```{r simulated-data-output}
# Create simulated data -----------------------
# simu_data <- data.frame(
#   id = sample(1:100000, size = 2000000, replace = TRUE),
#   code = sample_diag(n = 2000000, version = "ICD10_2011"),
#   stringsAsFactors = FALSE
# )
# simu_data <- simu_data[order(simu_data$id), ]
```

- Simulated 2,000,000 observations by sampling from a list of ICD-codes (provided by `comorbidity` package)
- Our function performs better than the `comorbidity` function on the large simulated data.

\vspace{3em}

\begin{columns}
  \begin{column}{0.48\textwidth}
    \textit{Our function:}
    \includegraphics[width=\textwidth]{simu_time_ours.png}
  \end{column}
  \begin{column}{0.48\textwidth}
    \textit{Comorbidity function:}
    \includegraphics[width=\textwidth]{simu_time_cmb.png}
  \end{column}
\end{columns}